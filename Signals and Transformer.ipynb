{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9279ff-cab9-42bb-b0d8-fb3f2e033a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow\n",
    "import gpflux\n",
    "import numpy as np\n",
    "import ruptures as rpt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tensorflow as tf\n",
    "from gpflux.helpers import construct_basic_kernel, construct_basic_inducing_variables\n",
    "from gpflux.layers import GPLayer\n",
    "from gpflux.experiment_support.plotting import plot_layer\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from ruptures.base import BaseCost\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5af82-818d-46b8-a29c-8e443d99b835",
   "metadata": {},
   "source": [
    "# Signal/Time Series Construction\n",
    "## Poisson Point Process\n",
    "We start by defining an intensity function for the Non-Homogeneous Poisson process (NHPP) and then generate a Point process using a thinning algorithm that can be found here (https://www.columbia.edu/~ks20/4703-Sigman/4703-07-Notes-PP-NSPP.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7eb52c0-678e-481d-b6d8-425e580c5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lam(x, a):\n",
    "    \"\"\"\n",
    "    Intensity function for the NHPP\n",
    "    \"\"\"\n",
    "    return a + np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2554a0dd-36df-4c7f-95ce-728864132176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_poisson_jumps(a, lambda_star, length=1000, seed=None):\n",
    "    \"\"\"\n",
    "    Thinning algorithm for generating a poisson point process signal.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    T = 0.01 * length\n",
    "    t = 0.0\n",
    "    n = 0\n",
    "    arrival_times = []\n",
    "    while True:\n",
    "        u = np.random.rand()\n",
    "        t = t - (1/lambda_star) * np.log(u)\n",
    "\n",
    "        if t > T:\n",
    "            break\n",
    "        u = np.random.rand()\n",
    "        lambda_t = lam(t, a)\n",
    "        if u <= lambda_t / lambda_star:\n",
    "            n += 1\n",
    "            arrival_times.append(t)\n",
    "    ts = np.linspace(0, T, length)\n",
    "    ys = np.searchsorted(arrival_times, ts)\n",
    "    return ts, ys, arrival_times, T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f86509-ffdf-4df0-a3ff-dd34e0e0aba9",
   "metadata": {},
   "source": [
    "## Deep Gaussian Process (DGP)\n",
    "We continue with defining the correlated noise of the signals. We start by defining a helper function for sampling layer kernels and hyperparameters. We choose to sample from four stationary kernels supported by GPFlow for each layer and vary their hyperparameters by sampling from the range [0.1, 5]. We then create a set of datapoints that are propagated through a number of predefined layers and save the output of the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37da82e2-8ed4-440f-bb87-a968f9771f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNELS = [gpflow.kernels.SquaredExponential,\n",
    "          gpflow.kernels.Matern12,\n",
    "          gpflow.kernels.Matern32,\n",
    "          gpflow.kernels.Matern52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8669bc43-46be-42c5-86ac-5a976d2b0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_sample_kernels(kernels, num_kernels, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    sampled_kernels = []\n",
    "    for i in range(num_kernels):\n",
    "        kernel = np.random.choice(kernels)()\n",
    "        lengthscales = np.random.uniform(0.1, 5.0)\n",
    "        variance = np.random.uniform(0.1, 5.0)\n",
    "        kernel.lengthscales.assign(lengthscales)\n",
    "        kernel.variance.assign(variance)\n",
    "        sampled_kernels.append(kernel)\n",
    "    return sampled_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ec840f-722b-43c4-9dcf-3868b468b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dgp_signal(datapoints, a, b, samples, kernels, num_layers, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    X = np.linspace(a, b, datapoints).reshape(-1, 1)\n",
    "    Z = X.copy()\n",
    "    M = Z.shape[0]\n",
    "    gp_layers = []\n",
    "    D = 1\n",
    "\n",
    "    ## Construct the each layer with inducing variables\n",
    "    for i in range(num_layers):\n",
    "        ind_var = construct_basic_inducing_variables(M, D, D, share_variables=True, z_init=Z.copy())\n",
    "        kernel = construct_basic_kernel(\n",
    "            kernels[i],\n",
    "            output_dim=D,\n",
    "            share_hyperparams=True)\n",
    "        gplayer = GPLayer(kernel, ind_var, datapoints, full_cov=True, num_samples=samples, mean_function=gpflow.mean_functions.Zero())\n",
    "        gp_layers.append(gplayer)\n",
    "    means, covs, samples = [], [], []\n",
    "    layer_input = X\n",
    "    for layer in gp_layers:\n",
    "        layer_output = layer(layer_input)\n",
    "\n",
    "        mean = layer_output.mean()\n",
    "        cov = layer_output.covariance()\n",
    "        sample = tf.convert_to_tensor(layer_output)  # generates num_samples samples...\n",
    "\n",
    "        layer_input = sample[0]  # for the next layer\n",
    "\n",
    "        means.append(mean.numpy().T)  # transpose to go from [1, N] to [N, 1]\n",
    "        covs.append(cov.numpy())\n",
    "        samples.append(sample.numpy())\n",
    "\n",
    "    return np.squeeze(samples[num_layers-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13a9d8-d295-49d4-a561-2f576cf9dd6d",
   "metadata": {},
   "source": [
    "Next is the definition of a batching function for extracting sequences to train the transformer model on. The final output is of dimension [batch_size, seq_len, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0087e52-ab1b-4aec-9e0b-fb9e266f28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_batch(samples, seq_len, batch_size, device=None):\n",
    "    \n",
    "    # Sample ids from each sample\n",
    "    indexes = torch.randint(0, len(samples), (batch_size,))\n",
    "\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    for i in indexes:\n",
    "        series = samples[i]\n",
    "        N = series.shape[0]\n",
    "\n",
    "        i = torch.randint(0, N - seq_len - 1, (1,)).item()\n",
    "        \n",
    "        x = series[i: i + seq_len]\n",
    "        y = series[i + 1: i + seq_len + 1]\n",
    "\n",
    "        x_batch.append(x)\n",
    "        y_batch.append(y)\n",
    "\n",
    "    x = torch.stack(x_batch).unsqueeze(-1)\n",
    "    y = torch.stack(y_batch).unsqueeze(-1)\n",
    "    if device is not None:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f95c2-bb29-44f7-9a66-3bc66fc95011",
   "metadata": {},
   "source": [
    "We can now define a function that will generate our sequences. The idea is to sample a single baseline poisson point process and then sample multiple noise signals. In the end we get a Tensor of shape [num_samples, length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9143d7c2-2351-47da-a8ac-23002e987a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences(a, lambda_star, length, kernels, num_layers, num_samples,poisson_seed=None, kernel_seed=None, dgp_seed=None):\n",
    "    xs, baseline, times, T = sample_poisson_jumps(a, lambda_star, length, poisson_seed)\n",
    "    kernels = randomly_sample_kernels(kernels, num_layers, kernel_seed)\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        samples.append(baseline + np.squeeze(sample_dgp_signal(len(xs), 0, T, 1, kernels, num_layers, dgp_seed)))\n",
    "    split = int(0.8 * len(samples))\n",
    "    samples = torch.tensor(\n",
    "        np.stack(samples, axis=0),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    print(\"Data generation completed\")\n",
    "    return samples[:split], samples[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0192cd14-23e1-494a-83d4-3e09da5204e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetBuilder(Dataset):\n",
    "    def __init__(self, samples, seq_len, stride=None, mode = 'deterministic'):\n",
    "        self.samples = samples\n",
    "        self.stride = stride if stride is not None else seq_len\n",
    "        # seq_len here will give us windows\n",
    "        self.seq_len = seq_len\n",
    "        self.mode = mode\n",
    "        self.windows = []\n",
    "        if mode == 'deterministic':\n",
    "            self.compute_valid_windows()\n",
    "\n",
    "    def compute_valid_windows(self):\n",
    "        num_samples, length = self.samples.shape\n",
    "\n",
    "        for sample_idx in range(num_samples):\n",
    "            start = 0\n",
    "            while start + self.seq_len <= length:\n",
    "                self.windows.append((sample_idx, start))\n",
    "                start += self.stride\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx, start = self.windows[idx]\n",
    "\n",
    "        window = self.samples[sample_idx, start : start + self.seq_len]\n",
    "        # [window_length, 1]\n",
    "        x = window[:-1].unsqueeze(-1) \n",
    "        y = window[1:].unsqueeze(-1)   \n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e5a62-48b8-469f-ba61-7414709b2b35",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "We now define a simple decoder-only Transformer model to be trained on the time series or signal data. This implementation is based on (https://huggingface.co/datasets/bird-of-paradise/transformer-from-scratch-tutorial/tree/main). To be able to adapt the architecture for continuous data, we linearly project the sequence points into the embedding dimension and then use a regression head to get the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee649f11-5c21-4c56-adcc-b9e153804bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some global variables\n",
    "SEQ_LEN = 50\n",
    "BATCH_SIZE = 16\n",
    "D_M = 128\n",
    "STEPS = 100\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b848fede-88de-4618-93ac-f59bf5708c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAtt(nn.Module):\n",
    "    def __init__(self, d_m, n_heads, dropout=0.1, bias=False):\n",
    "        super().__init__()\n",
    "        self.d_m = d_m\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_m // n_heads\n",
    "\n",
    "        # Full projections d_m*d_m\n",
    "        self.W_query = nn.Linear(d_m, d_m, bias=bias)\n",
    "        self.W_key = nn.Linear(d_m, d_m, bias=bias)\n",
    "        self.W_value = nn.Linear(d_m, d_m, bias=bias)\n",
    "\n",
    "        self.W_multi = nn.Linear(d_m, d_m, bias=bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, d_m = x.shape\n",
    "\n",
    "        query_matrix = self.W_query(x)\n",
    "        key_matrix = self.W_key(x)\n",
    "        value_matrix = self.W_value(x)\n",
    "\n",
    "        # (B, H, N, D)\n",
    "        query_heads = query_matrix.view(batch_size, sequence_length, self.n_heads, self.d_k).transpose(1,2)\n",
    "        key_heads = key_matrix.view(batch_size, sequence_length, self.n_heads, self.d_k).transpose(1,2)\n",
    "        value_heads = value_matrix.view(batch_size, sequence_length, self.n_heads, self.d_k).transpose(1,2)\n",
    "\n",
    "        # QK^T\n",
    "        qkt = torch.matmul(query_heads, key_heads.transpose(-1, -2))/ (self.d_k ** 0.5)\n",
    "\n",
    "        # mask\n",
    "        mask = torch.tril(torch.ones(sequence_length, sequence_length, device=x.device)).unsqueeze(0).unsqueeze(0)\n",
    "        add_mask = (1.0 - mask) * -1e9\n",
    "        masked_qkt = qkt + add_mask\n",
    "        #masked_qkt = qkt.masked_fill(mask == 0, float(\"-inf\"))\n",
    "\n",
    "        # Softmax\n",
    "        att_weights = F.softmax(masked_qkt, dim = -1)\n",
    "        \n",
    "        # Dropout\n",
    "        att_weights = self.dropout(att_weights)\n",
    "\n",
    "        # QK^T * V\n",
    "        attention = torch.matmul(att_weights, value_heads)\n",
    "\n",
    "        # Concatenate\n",
    "        output_matrix = attention.transpose(1, 2).contiguous().view(batch_size, sequence_length, d_m)\n",
    "\n",
    "        output = self.W_multi(output_matrix)\n",
    "\n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05a29548-166f-4901-a6d8-b09e631b1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_m, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(d_m, d_ff)\n",
    "        self.w2 = nn.Linear(d_ff, d_m)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.w1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.w2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df20ee94-dbbd-46c6-9ef4-61a592dc320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, d_m, n_heads):\n",
    "        super().__init__()\n",
    "        self.d_m = d_m\n",
    "        self.d_ff = 4*d_m\n",
    "        self.attention = MultiHeadAtt(self.d_m, n_heads)\n",
    "        self.feedforward = FeedForward(self.d_m, self.d_ff)\n",
    "\n",
    "        self.layernorm_att = nn.LayerNorm(self.d_m)\n",
    "        self.layernorm_ffn = nn.LayerNorm(self.d_m)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attention(self.layernorm_att(x))\n",
    "        x = x + self.feedforward(self.layernorm_ffn(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7798c558-6477-420c-84e8-fba297f78c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodings(nn.Module):\n",
    "    def __init__(self, d_m, max_len=2000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_m)\n",
    "\n",
    "        # pos\n",
    "        position = torch.arange(0, max_len, dtype = torch.float).unsqueeze(1)\n",
    "\n",
    "        # i\n",
    "        indexes = torch.arange(0, d_m,step=2, dtype= torch.float)\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position/(torch.tensor(10000) **(indexes/d_m)))\n",
    "        pe[:, 1::2] = torch.cos(position/(torch.tensor(10000) **(indexes/d_m)))\n",
    "        #Add batch_size\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67750fed-3287-4a4f-8e9c-53258abc2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, d_input, d_m, n_heads, n_layers, max_len=2000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_m = d_m\n",
    "        self.d_input = d_input\n",
    "\n",
    "        # Project time series to embedding dimension\n",
    "        self.input_linear = nn.Linear(d_input, d_m)\n",
    "\n",
    "        # Position encodings\n",
    "        self.pos = PositionalEncodings(d_m)\n",
    "\n",
    "        decoders = [Block(d_m, n_heads) for i in range(n_layers)]\n",
    "        self.blocks = nn.ModuleList(decoders)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layernorm = nn.LayerNorm(d_m)\n",
    "        # Project back to input dimension\n",
    "        self.output_linear = nn.Linear(d_m, d_input)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.input_linear(x) * math.sqrt(self.d_m)\n",
    "\n",
    "        x = self.pos(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.layernorm(x) # (B, seq_len, d_m)\n",
    "        x = self.output_linear(x)  # (B, seq_len, 1)\n",
    "        return x\n",
    "            \n",
    "    def generate(self, x, max_points, device='cpu'):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            x = x.to('cpu')\n",
    "            predictions = []\n",
    "\n",
    "            for i in range(max_points):\n",
    "                # Keep context\n",
    "                x_input = x[:, -x.size(1):, :]\n",
    "                # Get predictions (B, seq_len, 1)\n",
    "                pred = self(x_input)\n",
    "                # Keep only the last one\n",
    "                next_val = pred[:, -1:, :]\n",
    "                x = torch.cat([x, next_val], dim=1)\n",
    "                predictions.append(next_val.cpu())\n",
    "\n",
    "        return torch.cat(predictions, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb5b99-8ca3-4ebb-abb7-bfec8ed2df47",
   "metadata": {},
   "source": [
    "We can now create the training loop for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "52bd9c32-37ec-4670-b288-188d45a64d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader,\n",
    "          learning_rate=0.001, epochs=20):\n",
    "\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------- Training ----------\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for x_train, y_train in train_loader:\n",
    "            x_train = x_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            output = model(x_train)\n",
    "            loss = mse(output, y_train)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # ---------- Validation ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "\n",
    "                output = model(x_val)\n",
    "                loss = mse(output, y_val)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"Train: {train_loss:.4f} | \"\n",
    "            f\"Val: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed67efaf-ce7a-450a-8f42-3781b7eacd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_wave_sequences(\n",
    "    n_samples=1000,\n",
    "    length=300,\n",
    "    n_waves=3,\n",
    "    split_ratio=0.8,\n",
    "    seed=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate sine-wave time series and split into train / validation sets.\n",
    "\n",
    "    Returns:\n",
    "        train_samples: torch.FloatTensor (N_train, length)\n",
    "        val_samples:   torch.FloatTensor (N_val, length)\n",
    "    \"\"\"\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    samples = np.zeros((n_samples, length), dtype=np.float32)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        freq = np.random.uniform(0.5, 3.0, n_waves)\n",
    "        phase = np.random.uniform(0, 2 * np.pi, n_waves)\n",
    "        amp = np.random.uniform(0.5, 1.5, n_waves)\n",
    "\n",
    "        t = np.linspace(0, 4 * np.pi, length)\n",
    "        signal = np.zeros(length, dtype=np.float32)\n",
    "\n",
    "        for f, p, a in zip(freq, phase, amp):\n",
    "            signal += a * np.sin(f * t + p)\n",
    "\n",
    "        signal /= n_waves\n",
    "        samples[i] = signal\n",
    "\n",
    "    split = int(split_ratio * n_samples)\n",
    "\n",
    "    train_samples = torch.FloatTensor(samples[:split])\n",
    "    val_samples   = torch.FloatTensor(samples[split:])\n",
    "\n",
    "    return train_samples, val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "606daa56-8590-4afd-87f1-dd194a29c783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "train_samples, val_samples = generate_sine_wave_sequences()\n",
    "\n",
    "# Build datasets\n",
    "train_dataset = DatasetBuilder(\n",
    "    samples=train_samples,\n",
    "    seq_len=300,\n",
    "    stride=300,\n",
    "    mode=\"deterministic\"\n",
    ")\n",
    "\n",
    "val_dataset = DatasetBuilder(\n",
    "    samples=val_samples,\n",
    "    seq_len=300,\n",
    "    stride=300,\n",
    "    mode=\"deterministic\"\n",
    ")\n",
    "print(len(val_dataset))\n",
    "print(len(train_dataset))\n",
    "\n",
    "# Build dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "408596a9-d0f7-4197-a001-c33ac3626ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train: 0.0731 | Val: 0.0038\n",
      "Epoch 2/50 | Train: 0.0085 | Val: 0.0014\n",
      "Epoch 3/50 | Train: 0.0031 | Val: 0.0014\n",
      "Epoch 4/50 | Train: 0.0025 | Val: 0.0010\n",
      "Epoch 5/50 | Train: 0.0023 | Val: 0.0010\n",
      "Epoch 6/50 | Train: 0.0022 | Val: 0.0013\n",
      "Epoch 7/50 | Train: 0.0020 | Val: 0.0011\n",
      "Epoch 8/50 | Train: 0.0020 | Val: 0.0011\n",
      "Epoch 9/50 | Train: 0.0019 | Val: 0.0011\n",
      "Epoch 10/50 | Train: 0.0019 | Val: 0.0011\n",
      "Epoch 11/50 | Train: 0.0018 | Val: 0.0011\n",
      "Epoch 12/50 | Train: 0.0018 | Val: 0.0013\n",
      "Epoch 13/50 | Train: 0.0017 | Val: 0.0012\n",
      "Epoch 14/50 | Train: 0.0017 | Val: 0.0014\n",
      "Epoch 15/50 | Train: 0.0017 | Val: 0.0015\n",
      "Epoch 16/50 | Train: 0.0017 | Val: 0.0013\n",
      "Epoch 17/50 | Train: 0.0015 | Val: 0.0017\n",
      "Epoch 18/50 | Train: 0.0015 | Val: 0.0015\n",
      "Epoch 19/50 | Train: 0.0015 | Val: 0.0015\n",
      "Epoch 20/50 | Train: 0.0015 | Val: 0.0015\n",
      "Epoch 21/50 | Train: 0.0014 | Val: 0.0013\n",
      "Epoch 22/50 | Train: 0.0014 | Val: 0.0017\n",
      "Epoch 23/50 | Train: 0.0014 | Val: 0.0014\n",
      "Epoch 24/50 | Train: 0.0013 | Val: 0.0017\n",
      "Epoch 25/50 | Train: 0.0013 | Val: 0.0018\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model = TimeSeriesTransformer(\u001b[32m1\u001b[39m, D_M, \u001b[32m4\u001b[39m, \u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_los, val_los, model = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m torch.save(model.state_dict(), \u001b[33m'\u001b[39m\u001b[33mtransformer_model.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m model.eval()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, learning_rate, epochs)\u001b[39m\n\u001b[32m     19\u001b[39m y_train = y_train.to(device)\n\u001b[32m     21\u001b[39m opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m loss = mse(output, y_train)\n\u001b[32m     24\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mTimeSeriesTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     27\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layernorm(x) \u001b[38;5;66;03m# (B, seq_len, d_m)\u001b[39;00m\n\u001b[32m     32\u001b[39m x = \u001b[38;5;28mself\u001b[39m.output_linear(x)  \u001b[38;5;66;03m# (B, seq_len, 1)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     x = x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayernorm_att\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.feedforward(\u001b[38;5;28mself\u001b[39m.layernorm_ffn(x))\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mMultiHeadAtt.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     38\u001b[39m att_weights = F.softmax(masked_qkt, dim = -\u001b[32m1\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Dropout\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m att_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43matt_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# QK^T * V\u001b[39;00m\n\u001b[32m     44\u001b[39m attention = torch.matmul(att_weights, value_heads)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\functional.py:1418\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = TimeSeriesTransformer(1, D_M, 4, 3)\n",
    "train_los, val_los, model = train(model, train_loader, val_loader, epochs=50)\n",
    "torch.save(model.state_dict(), 'transformer_model.pth')\n",
    "model.eval()\n",
    "\n",
    "# pick one validation sample\n",
    "idx = torch.randint(0, val_samples.shape[0], (1,)).item()\n",
    "gt_sequence = val_samples[idx].unsqueeze(0).unsqueeze(-1).to(device)  \n",
    "generated = model.generate(gt_sequence[:, :150,:], 150)\n",
    "#signal_plot = gt_sequence[:,:50,:].squeeze(0).squeeze(-1).cpu().numpy()\n",
    "ground_truth = gt_sequence.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "generated_plot = generated.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.plot(ground_truth, label=\"Ground Truth\", linewidth=2)\n",
    "#plt.plot(generated_plot, label=\"Generated\", linestyle=\"--\")\n",
    "plt.plot(\n",
    "    range(150, 150 + len(generated_plot)),\n",
    "    generated_plot,\n",
    "    \"--\",\n",
    "    label=\"Generated (future)\"\n",
    ")\n",
    "plt.axvline(150, color=\"k\", linestyle=\":\", label=\"Prediction Start\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Synthetic vs Generated Time Series\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3a34834-6bae-4528-8783-da293a280193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_batch(samples, seq_len, batch_size, device=None):\n",
    "    #processing = []\n",
    "    #for sample in samples:\n",
    "        #processing.append(torch.tensor(sample, dtype=torch.float32))\n",
    "    \n",
    "    # Sample ids from each sample\n",
    "    indexes = torch.randint(0, len(samples), (batch_size,))\n",
    "\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    for i in indexes:\n",
    "        series = samples[i]\n",
    "        N = series.shape[0]\n",
    "\n",
    "        i = torch.randint(0, N - seq_len - 1, (1,)).item()\n",
    "        \n",
    "        x = series[i: i + seq_len]\n",
    "        y = series[i + 1: i + seq_len + 1]\n",
    "\n",
    "        x_batch.append(x)\n",
    "        y_batch.append(y)\n",
    "\n",
    "    x = torch.stack(x_batch).unsqueeze(-1)\n",
    "    y = torch.stack(y_batch).unsqueeze(-1)\n",
    "    if device is not None:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7632a42-ef0d-46c9-9997-a30e82b03714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_samples, val_samples, learning_rate=0.001, steps=5000, seed=None):\n",
    "    model = model.to(device)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    sc = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=steps)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    val_interval = 100  # Validate every 100 steps\n",
    "\n",
    "    for step in range(steps):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        x_train, y_train = sequence_batch(train_samples, 512, BATCH_SIZE, device=device)\n",
    "        opt.zero_grad()\n",
    "        output = model(x_train)\n",
    "        loss = mse(output, y_train)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sc.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # --- Periodic Validation ---\n",
    "        if (step + 1) % val_interval == 0 or step == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x_val, y_val = sequence_batch(val_samples, SEQ_LEN, BATCH_SIZE, device=device)\n",
    "                val_loss = mse(model(x_val), y_val).item()\n",
    "            val_losses.append((step + 1, val_loss))\n",
    "            print(f'Step {step+1}/{steps} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    return train_losses, val_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "998dc62a-9faf-4042-bafa-8f356c8b8c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/5000 | Train Loss: 0.6891 | Val Loss: 0.1404\n",
      "Step 100/5000 | Train Loss: 0.0220 | Val Loss: 0.0198\n",
      "Step 200/5000 | Train Loss: 0.0173 | Val Loss: 0.0152\n",
      "Step 300/5000 | Train Loss: 0.0161 | Val Loss: 0.0143\n",
      "Step 400/5000 | Train Loss: 0.0156 | Val Loss: 0.0145\n",
      "Step 500/5000 | Train Loss: 0.0147 | Val Loss: 0.0137\n",
      "Step 600/5000 | Train Loss: 0.0170 | Val Loss: 0.0141\n",
      "Step 700/5000 | Train Loss: 0.0139 | Val Loss: 0.0135\n",
      "Step 800/5000 | Train Loss: 0.0135 | Val Loss: 0.0123\n",
      "Step 900/5000 | Train Loss: 0.0126 | Val Loss: 0.0143\n",
      "Step 1000/5000 | Train Loss: 0.0139 | Val Loss: 0.0184\n",
      "Step 1100/5000 | Train Loss: 0.0121 | Val Loss: 0.0107\n",
      "Step 1200/5000 | Train Loss: 0.0116 | Val Loss: 0.0121\n",
      "Step 1300/5000 | Train Loss: 0.0115 | Val Loss: 0.0117\n",
      "Step 1400/5000 | Train Loss: 0.0115 | Val Loss: 0.0117\n",
      "Step 1500/5000 | Train Loss: 0.0123 | Val Loss: 0.0123\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m val_samples = processing[n_train:]\n\u001b[32m     18\u001b[39m model = TimeSeriesTransformer(\u001b[32m1\u001b[39m, D_M, \u001b[32m4\u001b[39m, \u001b[32m3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m train_los, val_los, model = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m model.eval()\n\u001b[32m     21\u001b[39m signal = random.choice(val_samples)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_samples, val_samples, learning_rate, steps, seed)\u001b[39m\n\u001b[32m     16\u001b[39m x_train, y_train = sequence_batch(train_samples, \u001b[32m512\u001b[39m, BATCH_SIZE, device=device)\n\u001b[32m     17\u001b[39m opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m loss = mse(output, y_train)\n\u001b[32m     20\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mTimeSeriesTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     27\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layernorm(x) \u001b[38;5;66;03m# (B, seq_len, d_m)\u001b[39;00m\n\u001b[32m     32\u001b[39m x = \u001b[38;5;28mself\u001b[39m.output_linear(x)  \u001b[38;5;66;03m# (B, seq_len, 1)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     x = x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayernorm_att\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.feedforward(\u001b[38;5;28mself\u001b[39m.layernorm_ffn(x))\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mMultiHeadAtt.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     38\u001b[39m att_weights = F.softmax(masked_qkt, dim = -\u001b[32m1\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Dropout\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m att_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43matt_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# QK^T * V\u001b[39;00m\n\u001b[32m     44\u001b[39m attention = torch.matmul(att_weights, value_heads)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\functional.py:1418\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def generate_synthetic_data(n_samples=1000, length=1024):\n",
    "    t = np.linspace(0, 5, length)\n",
    "    data = []\n",
    "    for _ in range(n_samples):\n",
    "        phase = np.random.rand() * 2*np.pi\n",
    "        freq = np.random.rand() * 0.5 + 0.1\n",
    "        signal = np.sin(freq * t + phase) + 0.1*np.random.randn(length)\n",
    "        data.append(signal)\n",
    "    return data\n",
    "\n",
    "samples = generate_synthetic_data(n_samples=100, length=1024)\n",
    "processing = []\n",
    "for sample in samples:\n",
    "    processing.append(torch.tensor(sample, dtype=torch.float32))\n",
    "n_train = int(0.8 * len(processing)) \n",
    "train_samples = processing[:n_train]\n",
    "val_samples = processing[n_train:]\n",
    "model = TimeSeriesTransformer(1, D_M, 4, 3)\n",
    "train_los, val_los, model = train(model, train_samples, val_samples)\n",
    "model.eval()\n",
    "signal = random.choice(val_samples)\n",
    "signal = signal.unsqueeze(0).unsqueeze(-1)\n",
    "generated = model.generate(signal[:, :50,:], 950)\n",
    "signal_plot = signal.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "generated_plot = generated.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.plot(signal_plot, label=\"Ground Truth\", linewidth=2)\n",
    "plt.plot(\n",
    "    range(50, 50 + len(generated_plot)),\n",
    "    generated_plot,\n",
    "    \"--\",\n",
    "    label=\"Generated (future)\"\n",
    ")\n",
    "plt.axvline(50, color=\"k\", linestyle=\":\", label=\"Prediction Start\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Synthetic vs Generated Time Series\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacff282-7904-4843-896c-b51421384b02",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "We can extract meaningful statistics from each signal using a changepoint estimator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0f276a5-5d1e-40e5-8a14-a7fdc46e2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cp(signal, pen):\n",
    "    return rpt.Pelt(model='l2').fit(signal).predict(pen=pen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24a0015c-5cf2-485d-8650-30246f3e0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signal_statistics(ys):\n",
    "    # First, estimate the changepoints\n",
    "    cps = estimate_cp(ys, 5)\n",
    "    cps = np.asarray(cps, dtype=int)\n",
    "    T = len(ys)\n",
    "    \n",
    "    # Get the boundaries of each changepoint\n",
    "    boundaries = np.concatenate(([0], cps))\n",
    "    # 1) We calculate the length of the regime change \n",
    "    inter_arrivals = np.diff(boundaries)\n",
    "\n",
    "    # 2) We calculate the rate of changepoints and their number\n",
    "    cp_rate = len(cps)/T\n",
    "    num_cps = len(cps)\n",
    "\n",
    "    means = []\n",
    "    variances = []\n",
    "    lengths = inter_arrivals\n",
    "    segments = [(boundaries[i],boundaries[i+1]) for i in range(len(boundaries)-1)]\n",
    "    for (start, end) in segments:\n",
    "        segment = ys[start:end]\n",
    "        means.append((segment.mean() - ys.mean()) / ys.std())\n",
    "        variances.append(segment.var())\n",
    "    # 3) Local statistics, means, variances and lengths\n",
    "    means = np.asarray(means)\n",
    "    variances = np.asarray(variances)\n",
    "\n",
    "    # 4) Jumps in means\n",
    "    jumps = np.diff(means)\n",
    "\n",
    "    # 5) correlation of lengths, everything but the last vs everything but the first\n",
    "    length_corr = (\n",
    "        np.corrcoef(lengths[:-1], lengths[1:])[0, 1]\n",
    "        if len(lengths) > 2 else np.nan\n",
    "    )\n",
    "\n",
    "    jump_length_corr = (\n",
    "        np.corrcoef(np.abs(jumps), lengths[1:])[0, 1]\n",
    "        if len(jumps) > 1 else np.nan\n",
    "    )\n",
    "\n",
    "    statistics =  {\n",
    "        \"cps\" : cps,\n",
    "        \"num_cps\" : num_cps,\n",
    "        \"cp_rate\": cp_rate,\n",
    "        \"inter_arrivals\": inter_arrivals,\n",
    "        \"lengths\": lengths,\n",
    "        \"means\": means,\n",
    "        \"variances\": variances,\n",
    "        \"jumps\": jumps,\n",
    "        \"length_corr\": length_corr,\n",
    "        \"jump_length_corr\": jump_length_corr,\n",
    "        }\n",
    "    return statistics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c49cc6-9610-4cdd-89d6-572156cad750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
